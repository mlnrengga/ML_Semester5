{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMq7/K4EDTPoJh+FscJFRyP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-roed0joy7u7","executionInfo":{"status":"ok","timestamp":1763634597831,"user_tz":-420,"elapsed":43439,"user":{"displayName":"Maulana Rengga Ramadan","userId":"05849588803174512002"}},"outputId":"2c9b5fe2-c0a4-4ca3-fd93-d0868fe72b32"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8826 - loss: 0.4040 - val_accuracy: 0.9567 - val_loss: 0.1387\n","Epoch 2/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9664 - loss: 0.1087 - val_accuracy: 0.9730 - val_loss: 0.0870\n","Epoch 3/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9791 - loss: 0.0673 - val_accuracy: 0.9710 - val_loss: 0.0896\n","Epoch 4/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9839 - loss: 0.0483 - val_accuracy: 0.9744 - val_loss: 0.0914\n","Epoch 5/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9870 - loss: 0.0403 - val_accuracy: 0.9763 - val_loss: 0.0829\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9712 - loss: 0.0989\n","Akurasi pada data uji: 0.9763\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten\n","from tensorflow.keras.utils import to_categorical\n","\n","# 1. Load dataset MNIST\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","# Normalisasi data (0-255 → 0-1)\n","X_train = X_train / 255.0\n","X_test = X_test / 255.0\n","\n","# One-hot encoding label\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","\n","# 2. Bangun model JST\n","model = Sequential([\n","    Flatten(input_shape=(28, 28)), # Ubah gambar 28x28 menjadi vektor\n","    Dense(128, activation='relu'), # Hidden layer 1\n","    Dense(64, activation='relu'),  # Hidden layer 2\n","    Dense(10, activation='softmax') # Output layer (10 kelas)\n","])\n","\n","# 3. Kompilasi model\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# 4. Latih model\n","model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))\n","\n","# 5. Evaluasi model\n","loss, acc = model.evaluate(X_test, y_test)\n","print(f\"Akurasi pada data uji: {acc:.4f}\")"]},{"cell_type":"markdown","source":["Coba dengan beberapa parameter lain:\n","\n","* Ubah jumlah neuron di hidden layer (misal: 256 dan 128).\n","\n","* Tambahkan satu hidden layer lagi.\n","\n","* Bandingkan akurasi dan waktu pelatihan.\n","\n","* Eksperimen dengan fungsi aktivasi Sigmoid vs ReLU."],"metadata":{"id":"l2Iph6MJ0YaR"}},{"cell_type":"code","source":["import tensorflow as tf\n","import time\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten\n","from tensorflow.keras.utils import to_categorical\n","\n","# 1. Load dataset MNIST\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","# Normalisasi data (0-255 → 0-1)\n","X_train = X_train / 255.0\n","X_test = X_test / 255.0\n","\n","# One-hot encoding label\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","\n","print(\"Data siap digunakan.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2N-uabC40ayA","executionInfo":{"status":"ok","timestamp":1763634690418,"user_tz":-420,"elapsed":479,"user":{"displayName":"Maulana Rengga Ramadan","userId":"05849588803174512002"}},"outputId":"31223d9e-7567-44a1-eb0d-e3948322e9de"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Data siap digunakan.\n"]}]},{"cell_type":"code","source":["print(\"--- Eksperimen 1: Ubah Neuron (256 & 128) ---\")\n","\n","# Bangun model\n","model_1 = Sequential([\n","    Flatten(input_shape=(28, 28)),     # Input layer (gambar 28x28)\n","    Dense(256, activation='relu'),     # Hidden layer 1 (256 neuron)\n","    Dense(128, activation='relu'),     # Hidden layer 2 (128 neuron)\n","    Dense(10, activation='softmax')    # Output layer (10 kelas)\n","])\n","\n","# Kompilasi\n","model_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Latih model & Hitung Waktu\n","start_time = time.time()\n","history_1 = model_1.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2, verbose=1)\n","end_time = time.time()\n","\n","# Evaluasi\n","loss_1, acc_1 = model_1.evaluate(X_test, y_test, verbose=0)\n","time_1 = end_time - start_time\n","\n","print(f\"\\n[Model 1] Akurasi: {acc_1:.4f}\")\n","print(f\"[Model 1] Waktu Pelatihan: {time_1:.2f} detik\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"joFm3hwk001e","executionInfo":{"status":"ok","timestamp":1763634846109,"user_tz":-420,"elapsed":51074,"user":{"displayName":"Maulana Rengga Ramadan","userId":"05849588803174512002"}},"outputId":"d78c6ff7-9396-4c52-8796-0cf7eeea4586"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Eksperimen 1: Ubah Neuron (256 & 128) ---\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8812 - loss: 0.4040 - val_accuracy: 0.9660 - val_loss: 0.1181\n","Epoch 2/5\n","\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9719 - loss: 0.0900 - val_accuracy: 0.9703 - val_loss: 0.1025\n","Epoch 3/5\n","\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9808 - loss: 0.0601 - val_accuracy: 0.9707 - val_loss: 0.0963\n","Epoch 4/5\n","\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9855 - loss: 0.0447 - val_accuracy: 0.9766 - val_loss: 0.0870\n","Epoch 5/5\n","\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9893 - loss: 0.0317 - val_accuracy: 0.9732 - val_loss: 0.1004\n","\n","[Model 1] Akurasi: 0.9765\n","[Model 1] Waktu Pelatihan: 49.93 detik\n"]}]},{"cell_type":"code","source":["print(\"--- Eksperimen 2: Tambah Extra Hidden Layer ---\")\n","\n","# Bangun model (3 Hidden Layers)\n","model_2 = Sequential([\n","    Flatten(input_shape=(28, 28)),\n","    Dense(256, activation='relu'),\n","    Dense(128, activation='relu'),\n","    Dense(64, activation='relu'),      # <--- Hidden layer tambahan\n","    Dense(10, activation='softmax')\n","])\n","\n","# Kompilasi\n","model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Latih model & Hitung Waktu\n","start_time = time.time()\n","history_2 = model_2.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2, verbose=1)\n","end_time = time.time()\n","\n","# Evaluasi\n","loss_2, acc_2 = model_2.evaluate(X_test, y_test, verbose=0)\n","time_2 = end_time - start_time\n","\n","print(f\"\\n[Model 2] Akurasi: {acc_2:.4f}\")\n","print(f\"[Model 2] Waktu Pelatihan: {time_2:.2f} detik\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wUAGYcW703xT","executionInfo":{"status":"ok","timestamp":1763634899991,"user_tz":-420,"elapsed":49530,"user":{"displayName":"Maulana Rengga Ramadan","userId":"05849588803174512002"}},"outputId":"83362b6e-b18b-4d0d-b498-f82e81b9ead6"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Eksperimen 2: Tambah Extra Hidden Layer ---\n","Epoch 1/5\n","\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8786 - loss: 0.4137 - val_accuracy: 0.9541 - val_loss: 0.1560\n","Epoch 2/5\n","\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9669 - loss: 0.1030 - val_accuracy: 0.9656 - val_loss: 0.1143\n","Epoch 3/5\n","\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9789 - loss: 0.0674 - val_accuracy: 0.9707 - val_loss: 0.1022\n","Epoch 4/5\n","\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9857 - loss: 0.0488 - val_accuracy: 0.9710 - val_loss: 0.1009\n","Epoch 5/5\n","\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9878 - loss: 0.0369 - val_accuracy: 0.9754 - val_loss: 0.0855\n","\n","[Model 2] Akurasi: 0.9771\n","[Model 2] Waktu Pelatihan: 48.86 detik\n"]}]},{"cell_type":"code","source":["print(\"--- Eksperimen 3: Ganti Aktivasi ke Sigmoid ---\")\n","\n","# Bangun model dengan Sigmoid\n","model_sigmoid = Sequential([\n","    Flatten(input_shape=(28, 28)),\n","    Dense(256, activation='sigmoid'),  # Ganti ReLU ke Sigmoid\n","    Dense(128, activation='sigmoid'),  # Ganti ReLU ke Sigmoid\n","    Dense(10, activation='softmax')\n","])\n","\n","# Kompilasi\n","model_sigmoid.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Latih model & Hitung Waktu\n","start_time = time.time()\n","history_sig = model_sigmoid.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2, verbose=1)\n","end_time = time.time()\n","\n","# Evaluasi\n","loss_sig, acc_sig = model_sigmoid.evaluate(X_test, y_test, verbose=0)\n","time_sig = end_time - start_time\n","\n","print(f\"\\n[Model Sigmoid] Akurasi: {acc_sig:.4f}\")\n","print(f\"[Model Sigmoid] Waktu Pelatihan: {time_sig:.2f} detik\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v11cgi0H05b9","executionInfo":{"status":"ok","timestamp":1763634960510,"user_tz":-420,"elapsed":50865,"user":{"displayName":"Maulana Rengga Ramadan","userId":"05849588803174512002"}},"outputId":"fb555ada-d3c6-4525-e947-b230bac4e5af"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Eksperimen 3: Ganti Aktivasi ke Sigmoid ---\n","Epoch 1/5\n","\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7906 - loss: 0.7793 - val_accuracy: 0.9342 - val_loss: 0.2168\n","Epoch 2/5\n","\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9433 - loss: 0.1896 - val_accuracy: 0.9559 - val_loss: 0.1500\n","Epoch 3/5\n","\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9604 - loss: 0.1325 - val_accuracy: 0.9669 - val_loss: 0.1154\n","Epoch 4/5\n","\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9726 - loss: 0.0900 - val_accuracy: 0.9673 - val_loss: 0.1030\n","Epoch 5/5\n","\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9795 - loss: 0.0691 - val_accuracy: 0.9737 - val_loss: 0.0883\n","\n","[Model Sigmoid] Akurasi: 0.9742\n","[Model Sigmoid] Waktu Pelatihan: 49.70 detik\n"]}]},{"cell_type":"markdown","source":["## 1. Ringkasan Hasil\n","| Model | Konfigurasi | Fungsi Aktivasi | Waktu Training (detik) | Akurasi Test |\n","| :--- | :--- | :--- | :--- | :--- |\n","| **Model 1** | 2 Hidden Layers (256, 128) | ReLU | **49.93 s** | **0.9765 (97.65%)** |\n","| **Model 2** | 3 Hidden Layers (256, 128, 64) | ReLU | **48.86 s** | **0.9771 (97.71%)** |\n","| **Model 3** | 2 Hidden Layers (256, 128) | Sigmoid | **49.70 s** | **0.9742 (97.42%)** |\n","\n","---\n","\n","## 2. Analisis Eksperimen\n","\n","### A. Pengaruh Jumlah Neuron (Model 1)\n","Dengan menggunakan konfigurasi neuron yang cukup besar (256 dan 128), model mampu mencapai akurasi yang sangat baik (**97.65%**) hanya dalam 5 epoch.\n","* **Observasi:** Kapasitas model sudah cukup mumpuni untuk menangkap pola tulisan tangan pada dataset MNIST.\n","\n","### B. Pengaruh Penambahan Layer (Model 2)\n","Menambahkan satu hidden layer ekstra (64 neuron) memberikan hasil akurasi tertinggi yaitu **97.71%**.\n","* **Akurasi:** Terjadi sedikit peningkatan akurasi dibandingkan Model 1 (+0.06%), menunjukkan bahwa jaringan yang lebih dalam (*deeper network*) sedikit membantu dalam membedakan fitur yang lebih spesifik.\n","* **Waktu:** Secara unik, waktu pelatihan tercatat sedikit lebih cepat (**48.86 detik**) dibandingkan Model 1. Hal ini kemungkinan besar disebabkan oleh variabilitas beban server Google Colab saat *runtime*, karena secara teoritis penambahan layer seharusnya menambah beban komputasi. Namun, perbedaannya sangat tipis (< 1 detik).\n","\n","### C. Perbandingan Aktivasi: ReLU vs Sigmoid (Model 3)\n","Mengganti fungsi aktivasi menjadi Sigmoid menghasilkan akurasi terendah di antara ketiga percobaan (**97.42%**).\n","* **Analisis:** Meskipun selisihnya tidak terlalu jauh, hasil ini mengonfirmasi bahwa **ReLU** bekerja lebih baik untuk *hidden layer* pada jaringan saraf modern dibandingkan Sigmoid. ReLU membantu model belajar lebih cepat dan menghindari masalah *vanishing gradient* yang membuat Sigmoid kurang efisien dalam mencapai loss minimal.\n","\n","---\n","\n","## 3. Kesimpulan Akhir\n","Berdasarkan data percobaan di atas:\n","1. **Konfigurasi Terbaik:** **Model 2** (3 Hidden Layers dengan ReLU) adalah yang terbaik karena menghasilkan akurasi tertinggi (97.71%).\n","2. **Fungsi Aktivasi:** **ReLU** terbukti lebih unggul dibandingkan Sigmoid untuk kasus ini.\n","3. **Efisiensi:** Penambahan layer meningkatkan akurasi tanpa mengorbankan waktu pelatihan secara signifikan pada skala dataset ini."],"metadata":{"id":"Kq0j-WTQ1Rx3"}}]}