{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM22blsMhyNm13shy5OEUyP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MUoiTX2ylJWi","executionInfo":{"status":"ok","timestamp":1763613938381,"user_tz":-420,"elapsed":564,"user":{"displayName":"Maulana Rengga Ramadan","userId":"05849588803174512002"}},"outputId":"9e5552e4-82ee-4a9e-a313-90566cf11e5b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0, Loss: 0.2760299675417221\n","Epoch 1000, Loss: 0.24983807326898044\n","Epoch 2000, Loss: 0.24828293953244163\n","Epoch 3000, Loss: 0.22807343060701327\n","Epoch 4000, Loss: 0.06648165024680566\n","Epoch 5000, Loss: 0.01817180328138443\n","Epoch 6000, Loss: 0.00914258810876471\n","Epoch 7000, Loss: 0.00587821794854689\n","Epoch 8000, Loss: 0.004263629646842818\n","Epoch 9000, Loss: 0.0033177195545649536\n","Prediksi:\n","[[0.05259611]\n"," [0.94078112]\n"," [0.95098331]\n"," [0.04620995]]\n"]}],"source":["import numpy as np\n","\n","# Dataset XOR\n","X = np.array([[0,0],[0,1],[1,0],[1,1]])\n","y = np.array([[0],[1],[1],[0]])\n","\n","# Parameter\n","input_size = 2\n","hidden_size = 2\n","output_size = 1\n","lr = 0.1\n","\n","# Inisialisasi bobot\n","W1 = np.random.randn(input_size, hidden_size)\n","b1 = np.zeros((1, hidden_size))\n","W2 = np.random.randn(hidden_size, output_size)\n","b2 = np.zeros((1, output_size))\n","\n","# Fungsi aktivasi\n","def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))\n","\n","def sigmoid_derivative(x):\n","    return x * (1 - x)\n","\n","# Training\n","for epoch in range(10000):\n","    # Forward pass\n","    z1 = np.dot(X, W1) + b1\n","    a1 = sigmoid(z1)\n","    z2 = np.dot(a1, W2) + b2\n","    a2 = sigmoid(z2)\n","\n","    # Hitung error\n","    error = y - a2\n","\n","    # Backpropagation\n","    d_a2 = error * sigmoid_derivative(a2)\n","    d_W2 = np.dot(a1.T, d_a2)\n","    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n","\n","    d_a1 = np.dot(d_a2, W2.T) * sigmoid_derivative(a1)\n","    d_W1 = np.dot(X.T, d_a1)\n","    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n","\n","    # Update bobot\n","    W1 += lr * d_W1\n","    b1 += lr * d_b1\n","    W2 += lr * d_W2\n","    b2 += lr * d_b2\n","\n","    if epoch % 1000 == 0:\n","        loss = np.mean(np.square(error))\n","        print(f\"Epoch {epoch}, Loss: {loss}\")\n","\n","# Output akhir\n","print(\"Prediksi:\")\n","print(a2)"]},{"cell_type":"markdown","source":["## Tugas 1:\n","\n","* Ubah jumlah neuron hidden layer menjadi 3.\n","\n","* Bandingkan hasil loss dengan konfigurasi awal.\n","\n","* Tambahkan fungsi aktivasi ReLU dan bandingkan hasil.\n"],"metadata":{"id":"Cz_2JeqDn75i"}},{"cell_type":"code","source":["# --- PERSIAPAN DATA & LIBRARY ---\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","# Load Data\n","data = load_iris()\n","X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42)\n","\n","# Scaling (Wajib untuk ANN)\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# --- TUGAS 1: Ubah jumlah neuron hidden layer menjadi 3 ---\n","# Kita buat model dengan hidden_layer_sizes=(3,)\n","mlp_tugas1 = MLPClassifier(hidden_layer_sizes=(3,), activation='logistic', solver='lbfgs', max_iter=1000, random_state=42)\n","mlp_tugas1.fit(X_train, y_train)\n","\n","print(f\"Loss model Tugas 1: {mlp_tugas1.loss_:.5f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_lJQ2tv8n4Jf","executionInfo":{"status":"ok","timestamp":1763614707533,"user_tz":-420,"elapsed":340,"user":{"displayName":"Maulana Rengga Ramadan","userId":"05849588803174512002"}},"outputId":"bf0bcdb7-a8c1-4f63-ceaf-a4e0ff8e658a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Loss model Tugas 1: 0.03722\n"]}]},{"cell_type":"code","source":["# --- TUGAS 2: Bandingkan hasil loss dengan konfigurasi awal ---\n","\n","# 1. Latih model konfigurasi awal (Asumsi: 5 neuron, activation logistic)\n","mlp_awal = MLPClassifier(hidden_layer_sizes=(5,), activation='logistic', solver='lbfgs', max_iter=1000, random_state=42)\n","mlp_awal.fit(X_train, y_train)\n","\n","# 2. Ambil nilai loss dari kedua model\n","loss_awal = mlp_awal.loss_\n","loss_tugas1 = mlp_tugas1.loss_ # Variabel dari Cell 1\n","\n","# 3. Tampilkan Perbandingan\n","print(\"=== PERBANDINGAN LOSS ===\")\n","print(f\"Loss Konfigurasi Awal (5 Neuron): {loss_awal:.5f}\")\n","print(f\"Loss Tugas 1 (3 Neuron)         : {loss_tugas1:.5f}\")\n","\n","selisih = loss_tugas1 - loss_awal\n","if selisih > 0:\n","    print(f\"Analisis: Loss NAIK sebesar {selisih:.5f}. (Mengurangi neuron dapat mengurangi kemampuan model fitting).\")\n","else:\n","    print(f\"Analisis: Loss TURUN sebesar {abs(selisih):.5f}. (Model lebih efisien).\")"],"metadata":{"id":"UJuVN_lboQ30","executionInfo":{"status":"ok","timestamp":1763614725466,"user_tz":-420,"elapsed":252,"user":{"displayName":"Maulana Rengga Ramadan","userId":"05849588803174512002"}},"outputId":"d3b81b28-e782-4da5-f08a-c012152571c3","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["=== PERBANDINGAN LOSS ===\n","Loss Konfigurasi Awal (5 Neuron): 0.02160\n","Loss Tugas 1 (3 Neuron)         : 0.03722\n","Analisis: Loss NAIK sebesar 0.01562. (Mengurangi neuron dapat mengurangi kemampuan model fitting).\n"]}]},{"cell_type":"code","source":["# --- TUGAS 3: Tambahkan fungsi aktivasi ReLU dan bandingkan ---\n","\n","# 1. Buat model dengan 3 neuron (sama seperti Tugas 1) tapi activation='relu'\n","mlp_relu = MLPClassifier(hidden_layer_sizes=(3,), activation='relu', solver='lbfgs', max_iter=1000, random_state=42)\n","mlp_relu.fit(X_train, y_train)\n","\n","# 2. Ambil nilai loss\n","loss_relu = mlp_relu.loss_\n","\n","# 3. Bandingkan dengan Tugas 1 (sama-sama 3 neuron, beda aktivasi)\n","print(\"=== PERBANDINGAN AKTIVASI (3 Neuron) ===\")\n","print(f\"Loss dengan Logistic (Tugas 1): {loss_tugas1:.5f}\")\n","print(f\"Loss dengan ReLU (Tugas 3)    : {loss_relu:.5f}\")\n","\n","if loss_relu < loss_tugas1:\n","    print(\"Kesimpulan: ReLU memberikan error (loss) yang lebih KECIL dibanding Logistic pada dataset ini.\")\n","else:\n","    print(\"Kesimpulan: ReLU memberikan error (loss) yang lebih BESAR dibanding Logistic pada dataset ini.\")"],"metadata":{"id":"miDlTsBzoVd0","executionInfo":{"status":"ok","timestamp":1763614744681,"user_tz":-420,"elapsed":56,"user":{"displayName":"Maulana Rengga Ramadan","userId":"05849588803174512002"}},"outputId":"40577d43-2ca2-4065-89dc-13c89829b172","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["=== PERBANDINGAN AKTIVASI (3 Neuron) ===\n","Loss dengan Logistic (Tugas 1): 0.03722\n","Loss dengan ReLU (Tugas 3)    : 0.04456\n","Kesimpulan: ReLU memberikan error (loss) yang lebih BESAR dibanding Logistic pada dataset ini.\n"]}]}]}